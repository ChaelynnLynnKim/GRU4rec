{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralCF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTMNs9GHr3ymeTaXDcVbbA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaelynnLynnKim/GRU4rec/blob/main/NeuralCF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nw8Df7QOozP",
        "outputId": "135c63b1-1bbe-4bd8-a403-c8e23d0b6e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural-collaborative-filtering'...\n",
            "remote: Enumerating objects: 135, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/37)\u001b[K\rremote: Counting objects:   5% (2/37)\u001b[K\rremote: Counting objects:   8% (3/37)\u001b[K\rremote: Counting objects:  10% (4/37)\u001b[K\rremote: Counting objects:  13% (5/37)\u001b[K\rremote: Counting objects:  16% (6/37)\u001b[K\rremote: Counting objects:  18% (7/37)\u001b[K\rremote: Counting objects:  21% (8/37)\u001b[K\rremote: Counting objects:  24% (9/37)\u001b[K\rremote: Counting objects:  27% (10/37)\u001b[K\rremote: Counting objects:  29% (11/37)\u001b[K\rremote: Counting objects:  32% (12/37)\u001b[K\rremote: Counting objects:  35% (13/37)\u001b[K\rremote: Counting objects:  37% (14/37)\u001b[K\rremote: Counting objects:  40% (15/37)\u001b[K\rremote: Counting objects:  43% (16/37)\u001b[K\rremote: Counting objects:  45% (17/37)\u001b[K\rremote: Counting objects:  48% (18/37)\u001b[K\rremote: Counting objects:  51% (19/37)\u001b[K\rremote: Counting objects:  54% (20/37)\u001b[K\rremote: Counting objects:  56% (21/37)\u001b[K\rremote: Counting objects:  59% (22/37)\u001b[K\rremote: Counting objects:  62% (23/37)\u001b[K\rremote: Counting objects:  64% (24/37)\u001b[K\rremote: Counting objects:  67% (25/37)\u001b[K\rremote: Counting objects:  70% (26/37)\u001b[K\rremote: Counting objects:  72% (27/37)\u001b[K\rremote: Counting objects:  75% (28/37)\u001b[K\rremote: Counting objects:  78% (29/37)\u001b[K\rremote: Counting objects:  81% (30/37)\u001b[K\rremote: Counting objects:  83% (31/37)\u001b[K\rremote: Counting objects:  86% (32/37)\u001b[K\rremote: Counting objects:  89% (33/37)\u001b[K\rremote: Counting objects:  91% (34/37)\u001b[K\rremote: Counting objects:  94% (35/37)\u001b[K\rremote: Counting objects:  97% (36/37)\u001b[K\rremote: Counting objects: 100% (37/37)\u001b[K\rremote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 135 (delta 28), reused 23 (delta 23), pack-reused 98\u001b[K\n",
            "Receiving objects: 100% (135/135), 14.30 MiB | 17.58 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/yihong-chen/neural-collaborative-filtering.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://files.grouplens.org/datasets/movielens/ml-1m.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6a7oo4oOuSa",
        "outputId": "eef811c4-34c4-4abf-c4ac-5fd8bae39f61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-06 09:02:34--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  18.4MB/s    in 0.3s    \n",
            "\n",
            "2022-06-06 09:02:34 (18.4 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip ml-1m.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fBNlrRrQIjX",
        "outputId": "bd53effa-dbb2-4d00-f59b-7ab4d9d9cb38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cd neural-collaborative-filtering && python /content/neural-collaborative-filtering/src/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyEKWH14P9La",
        "outputId": "c6931fcb-7b4c-401b-c9fd-3b5472180884"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/neural-collaborative-filtering/src/train.py\", line 3, in <module>\n",
            "    from gmf import GMFEngine\n",
            "  File \"/content/neural-collaborative-filtering/src/gmf.py\", line 2, in <module>\n",
            "    from engine import Engine\n",
            "  File \"/content/neural-collaborative-filtering/src/engine.py\", line 3, in <module>\n",
            "    from tensorboardX import SummaryWriter\n",
            "ModuleNotFoundError: No module named 'tensorboardX'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/guoyang9/NCF.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACv-wYjGO9uW",
        "outputId": "834d48e8-b191-482c-8dfb-6fee7e798a67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NCF'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 59 (delta 21), reused 18 (delta 18), pack-reused 31\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/hexiangnan/neural_collaborative_filtering.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV_x2nYyRIcm",
        "outputId": "5cd11be7-a172-4bf3-f01f-f0014ef584a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural_collaborative_filtering'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Total 66 (delta 0), reused 0 (delta 0), pack-reused 66\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ml:\n",
        "--batch_size=256\n",
        "--lr=0.001 \n",
        "--factor_num=16\n",
        "\n",
        "HR: 0.690 at epoch 08\n",
        "NDCG: 0.415 at epoch 07"
      ],
      "metadata": {
        "id": "KGPdZ8vobMea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cd NCF && python main.py --batch_size=256 --lr=0.001 --factor_num=16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIWS4yAJSEmq",
        "outputId": "ccab09de-3d68-4b30-aa28-c1ead209d727"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "The time elapse of epoch 000 is: 00: 02: 52\n",
            "HR: 0.617\tNDCG: 0.355\n",
            "The time elapse of epoch 001 is: 00: 02: 52\n",
            "HR: 0.659\tNDCG: 0.386\n",
            "The time elapse of epoch 002 is: 00: 02: 50\n",
            "HR: 0.666\tNDCG: 0.394\n",
            "The time elapse of epoch 003 is: 00: 02: 52\n",
            "HR: 0.679\tNDCG: 0.402\n",
            "The time elapse of epoch 004 is: 00: 02: 50\n",
            "HR: 0.683\tNDCG: 0.408\n",
            "The time elapse of epoch 005 is: 00: 02: 50\n",
            "HR: 0.692\tNDCG: 0.414\n",
            "The time elapse of epoch 006 is: 00: 02: 54\n",
            "HR: 0.687\tNDCG: 0.413\n",
            "The time elapse of epoch 007 is: 00: 02: 58\n",
            "HR: 0.685\tNDCG: 0.415\n",
            "The time elapse of epoch 008 is: 00: 02: 52\n",
            "HR: 0.690\tNDCG: 0.414\n",
            "The time elapse of epoch 009 is: 00: 02: 50\n",
            "HR: 0.689\tNDCG: 0.415\n",
            "The time elapse of epoch 010 is: 00: 02: 51\n",
            "HR: 0.688\tNDCG: 0.416\n",
            "The time elapse of epoch 011 is: 00: 02: 53\n",
            "HR: 0.685\tNDCG: 0.415\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 119, in <module>\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm5qLllPTCje",
        "outputId": "015ae109-4dce-4a70-d3f5-82a9d023f768"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l22kNHFnSpA2",
        "outputId": "e79a12ed-4d73-437e-d842-7def4867b1a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun  6 09:14:04 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bA1Xrh8nStf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}